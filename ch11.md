[[monitoring]]
== Monitoring
The term _observability_ is often used to describe a desirable attribute of distributed systems. Observability means having visibility into the various components of a system in order to detect, predict, and perhaps even prevent the complex failures that can occur in distributed systems. Failures in individual components can affect other components in turn, and multiple failures can interact in unforeseen ways, leading to system-wide outages. Common elements of an observability strategy for a system include metrics, logging, and tracing.

In this chapter, you'll learn how Cassandra supports these elements of observability and how to use available tools to monitor and understand important events in the life cycle of your Cassandra cluster. We'll look at some simple ways to see what's going on, such as changing the logging levels and understanding the output.

To begin, let's discuss how Cassandra uses the Java Management Extensions (JMX) to expose information about its internal operations and allow the dynamic configuration of some of its behavior. That will give you a basis to learn how to monitor Cassandra with various tools.

[[monitoring_cassandra_with_jmx]]
=== Monitoring Cassandra with JMX

Cassandra makes use of JMX to enable remote management of your nodes. JMX started as Java Specification Request (JSR) 160 and has been a core part of Java since version 5.0. You can read more about the JMX implementation in Java by examining the `java.lang.management` package.

JMX is a Java API that provides management of applications in two key ways. First, it allows you to understand your application's health and overall performance in terms of memory, threads, and CPU usage—things that apply to any Java application. Second, it allows you to work with specific aspects of your application that you have instrumented.

_Instrumentation_ refers to putting a wrapper around application code that provides hooks from the application to the JVM in order to allow the JVM to gather data that external tools can use. Such tools include monitoring agents, data analysis tools, profilers, and more. JMX allows you not only to view such data but also, if the application enables it, to manage your application at runtime by updating values.

Many popular Java applications are instrumented using JMX, including the JVM itself, the Tomcat application server, and Cassandra. <<the_jmx_architecture>> shows the JMX architecture as used by Cassandra.

[[the_jmx_architecture]]
.The JMX architecture
image::images/cdg3_1101.png[]

The JMX architecture is simple. The JVM collects information from the underlying operating system. The JVM itself is instrumented, so many of its features are exposed, including memory management and garbage collection, threading and deadlock detection, classloading, and logging.

An instrumented Java application (such as Cassandra) runs on top of this, also exposing some of its features as manageable objects. The Java Development Kit (JDK) includes an MBean server that makes the instrumented features available over a remote protocol to a JMX management application. The JVM also offers management capabilities via the Simple Network Monitoring Protocol (SNMP), which may be useful if you are using SMTP monitoring tools such as Nagios or Zenoss.

[NOTE]
.Connecting Remotely via JMX
====
By default, Cassandra runs with JMX enabled for local access only. To enable remote access, edit the file _&lt;cassandra-home&gt;/cassandra-env.sh_ (or _cassandra-env.ps1_ on Windows). Search for &ldquo;JMX&rdquo; to find the section of the file with options to control the JMX port and other local/remote connection settings. For example, in public cloud deployments it is often required to override the setting of the +java.rmi.server.hostname+ command line argument passed to the JVM to enable remote clients to access JMX.
====

Within a given application, you can manage only what the application developers have made available for you to manage. Luckily, the Cassandra developers have instrumented large parts of the database engine, making management via JMX fairly straightforward.

[[jmx_clients]]
.JMX Clients
****
In this chapter we'll focus on Nodetool, but there are plenty of other JMX clients available:

_JConsole_::
The JConsole tool ships with the standard Java Development Kit. It provides a graphical user interface client for working with MBeans and can be used for local or remote management. JConsole is an easy choice when you're looking for a JMX client, because it's easy to use and doesn't require a separate install

_Oracle Java Mission Control and Visual VM_:: 
These tools also ship with the Oracle JDK and provide more robust metrics, diagnostics, and visualizations for memory usage, threads, garbage collection, and others. The main comparison between the two is that Visual VM is an open source project available under the GNU license, while Mission Control provides a deeper level of integration with the Oracle JVM via a framework called Flight Control.
+
Java Mission Control can be run via the command `$JAVA_HOME/bin/jmc`, and Visual VM via the command `$JAVA_HOME/bin/jvisualvm`. Both are suitable for usage in development and production environments.

_MX4J_:: 
The Management Extensions for Java (MX4J) project provides an open source implementation of JMX, including tooling, such as an embedded web interface to JMX using HTTP/HTML. This allows interactions with JMX via a standard web browser.
+
To integrate MX4J into a Cassandra installation, download the http://mx4j.sourceforge.net/[_mx4j_tools.jar_ library], save the JAR file in the _lib_ directory of your Cassandra installation, and configure the `MX4J_ADDRESS` and `MX4J_PORT` options in _conf/cassandra-env.sh_.

_Jmxterm_:: 
Jmxterm is a command-line JMX client that allows access to a JMX server without a graphical interface. This can be especially useful when working in cloud environments, as the graphical tools are typically more resource intensive.
+
Jmxterm is an open source Java project available from the http://wiki.cyclopsgroup.org/jmxterm[CyclopsGroup].

_IDE Integrations_:: 
    You can also find JMX clients that integrate with popular IDEs; for example, https://code.google.com/p/eclipse-jmx[eclipse-jmx].A _managed bean_, or MBean, is a special type of Java bean that represents a single manageable resource inside the JVM. MBeans interact with an MBean server to make their functions remotely available. Many classes in Cassandra are exposed as MBeans, which means in practical terms that they implement a custom interface that describes attributes they expose and operations that need to be implemented and for which the JMX agent will provide hooks.

----
public interface CompactionManagerMBean
{
    public List<Map<String, String>> getCompactions();
    public List<String> getCompactionSummary();
    public TabularData getCompactionHistory();

    public void forceUserDefinedCompaction(String dataFiles);
    public void stopCompaction(String type);
    public void stopCompactionById(String compactionId);

    public int getCoreCompactorThreads();
    public void setCoreCompactorThreads(int number);

    ...
}
----

Some simple values in the application are exposed as _attributes_. An example of this is the `coreCompactorThreads` attribute, for which getter and setter operations are provided. Other attributes that are read-only are the current `compactions` in progress, the `compactionSummary`, and the `compactionHistory`. You can refresh to see the most recent values, but that's pretty much all you can do with them. Because these values are maintained internally in the JVM, it doesn't make sense to set them externally (they're derived from actual events, and are not configurable).

MBeans can also make _operations_ available to the JMX agent that let you execute some useful action. The `forceUserDefinedCompaction()` and `stopCompaction()` methods are operations that you can use to force a compaction to occur or stop a running compaction from a JMX client.

As you can see by this MBean interface definition, there's no magic going on. This is just a regular interface defining the set of operations. The `CompactionManager` class implements this interface and does the work of registering itself with the MBean server for the JMX attributes and operations that it maintains locally:

----
public static final String MBEAN_OBJECT_NAME =
    "org.apache.cassandra.db:type=CompactionManager";

static
{
    instance = new CompactionManager();
    MBeanWrapper.instance.registerMBean(instance, MBEAN_OBJECT_NAME);
}
----

Note that the MBean is registered in the domain `org.apache.cassandra.db` with a type of `CompactionManager`. The attributes and operations exposed by this MBean appear under `org.apache.cassandra.db &gt; CompactionManager` in JMX clients.

In the following sections, you'll learn about some of the key MBeans that Cassandra exposes to allow monitoring and management via JMX. Many of these MBeans correspond to the services and managers introduced in <<the_cassandra_architecture>>. In most cases, the operations and attributes exposed by the MBeans are accessible via `nodetool` commands discussed throughout this book.

[[database_mbeans]]
==== Database MBeans

These are the Cassandra classes related to the core database itself that are exposed to clients in the `org.apache.cassandra.db` domain. There are many MBeans in this domain, but we'll focus on a few key ones related to the data the node is responsible for storing, including caching, the commit log, and metadata about specific tables.

[[storage_service_mbean]]
===== Storage Service MBean

Because Cassandra is a database, it's essentially a very sophisticated storage program; therefore, Cassandra's storage engine as implemented in the `org.apache.cassandra.service.StorageService` is an essential focus of monitoring and management. The corresponding MBean for this service is the `StorageServiceMBean`, which provides many useful attributes and operations.

The MBean exposes identifying information about the node, including its host ID, the cluster name, and partitioner in use. It also allows you to inspect the node's `OperationMode`, which reports `normal` if everything is going smoothly (other possible states are `leaving`, `joining`, `decommissioned`, and `client`). These attributes are used by `nodetool` commands such as `describecluster` and `info`.

You can also view the current set of live nodes, as well as the set of unreachable nodes in the cluster. If any nodes are unreachable, Cassandra will tell you their IP addresses in the `UnreachableNodes` attribute.

To get an understanding of how much data is stored on each node, you can use the `getLoadMapWithPort()` method, which will return a Java Map with keys of IP addresses with values of their corresponding storage loads. You can also use the `effectiveOwnershipWithPort(String keyspace)` operation to access the percentage of the data in a keyspace owned by each node. This information is used in the `nodetool ring` and +status+ commands.

If you're looking for which nodes own a certain partition key, you can use the `getNaturalEndpointsWithPort()` operation. Pass it the keyspace name, table name, and the partition key for which you want to find the endpoint value, and it will return a list of IP addresses (with port number) that are responsible for storing this key.

You can also use the `describeRingWithPortJMX()` operation to get a list of token ranges in the cluster, including their ownership by nodes in the cluster. This is used by the `nodetool describering` operation.

There are many standard maintenance operations that the `StorageServiceMBean` affords you, including `resumeBootstrap()`, `joinRing()`, `flush()`, `truncate()`, `repairAsync()`, `cleanup()`, `scrub()`, `drain()`, `removeNode()`, `decommission()`, and operations to start and stop gossip, and the native transport. We'll dig into the `nodetool` commands that correspond to these operations in <<maintenance>>.

If you want to change Cassandra's logging configuration at runtime without interrupting service (as you'll see in <<logging-id1>>), you can invoke the +getLoggingLevels()+ method to see the currently configured levels, and then use the `setLoggingLevel(String classQualifier, String level)` method to override the log level for classes matching the pattern you provide.

[[storage_proxy_mbean]]
===== Storage Proxy MBean

As you learned in <<the_cassandra_architecture>>, the `org.apache.cassandra.service.StorageProxy` provides a layer on top of the `StorageService` to handle client requests and inter-node communications. The `StorageProxyMBean` provides the ability to check and set timeout values for various operations, including read and write. Along with many other attributes exposed by Cassandra's MBeans, these timeout values would originally be specified in the _cassandra.yaml_ file. Setting these attributes takes effect only until the next time the node is restarted, whereupon they'll be initialized to the values in the configuration file.

This MBean also provides access to hinted handoff settings such as the maximum time window for storing hints. Hinted handoff statistics include `getTotalHints()` and `getHintsInProgress()`. You can disable hints for nodes in a particular data center with the `disableHintsForDC()` operation.

You can also turn this node's participation in hinted handoff on or off via `setHintedHandoffEnabled()`, or check the current status via `getHintedHandoffEnabled()`. These are used by `nodetool`'s `enablehandoff`, `disablehandoff`, and `statushandoff` commands, respectively.

[[hints_service_mbean]]
===== Hints Service MBean

In addition to the hinted handoff operations on the `StorageServiceMBean`, Cassandra provides more hinted handoff controls via the `org.apache.cassandra.hints.HintsServiceMBean`. The MBean exposes the ability to pause and resume hint delivery You can delete hints that are stored up for a specific node with `deleteAllHintsForEndpoint()`.

Additionally, you can pause and resume hint delivery to all nodes with `pauseDispatch()` and `resumeDispatch()`. You can delete stored hints for all nodes with the `deleteAllHints()` operation, or for a specific node with `deleteAllHintsForEndpoint()`. These are used by `nodetool`'s `pausehandoff`, `resumehandoff`, and `truncatehints` commands.

[[column_family_store_mbean]]
===== Column Family Store MBean

Cassandra registers an instance of the `org.apache.cassandra.db.ColumnFamilyStoreMBean` for each table stored in the node under `org.apache.cassandra.db &gt; Tables` (this is a legacy name: tables were known as column families in early versions of Cassandra).

The `ColumnFamilyStoreMBean` provides access to the compaction and compression settings for each table. This allows you to temporarily override these settings on a specific node. The values will be reset to those configured on the table schema when the node is restarted.

The MBean also exposes a lot of information about the node's storage of data for this table on disk. The `getSSTableCountPerLevel()` operation provides a list of how many SStables are in each tier. The `estimateKeys()` operation provides an estimate of the number of partitions stored on this node. Taken together, this information can give you some insight as to whether invoking the `forceMajorCompaction()` operation for this table might help free space on this node and increase read performance.

There is also a `trueSnapshotsSize()` operation that allows you to determine the size of SSTable shapshots which are no longer active. A large value here indicates that you should consider deleting these snapshots, possibly after making an archive copy.

Because Cassandra stores indexes as tables, there is also a `ColumnFamilyStoreMBean` instance for each indexed column, available under `org.apache.cassandra.db &gt; IndexTables` (previously `IndexColumnFamilies`), with the same attributes and operations.

[[commit_log_mbean]]
===== Commit Log MBean

The `org.apache.cassandra.db.commitlog.CommitLogMBean` exposes attributes and operations that allow you to learn about the current state of commit logs. The `CommitLogMBean` also exposes the `recover()` operation which can be used to restore database state from archived commit log files.

The default settings that control commit log recovery are specified in the _conf/commitlog_archiving.properties_ file, but can be overridden via the MBean. You'll learn more about data recovery in <<maintenance>>.

[[compaction_manager_mbean]]
===== Compaction Manager MBean

You've already taken a peek inside the source of the `org.apache.cassandra.db.compaction.CompactionManagerMBean` to see how it interacts with JMX, but we didn't really talk about its purpose. This MBean allows you to get statistics about compactions performed in the past, and the ability to force compaction of specific SSTable files we identify by calling the `forceUserDefinedCompaction` method of the `CompactionManager` class. This MBean is leveraged by `nodetool` commands, including `compact`, `compactionhistory`, and `compactionstats`.

[[cache_service_mbean]]
===== Cache Service MBean

The `org.apache.cassandra.service.CacheServiceMBean` provides access to Cassandra's key cache, row cache, and counter cache under the domain `org.apache.cassandra.db &gt; Caches`. The information available for each cache includes the maximum size and time duration to cache items, and the ability to invalidate each cache.There are plenty of additional MBeans outside the core database engine that help manage how a Cassandra node relates to other nodes in its cluster, including snitching, gossip and failure detection, hinted handoff, messaging, and streaming.

[[gossiper_mbean]]
===== Gossiper MBean

The `org.apache.cassandra.gms.GossiperMBean` provides access to the work of the `Gossiper`.

We've already discussed how the `StorageServiceMBean` reports which nodes are unreachable. Based on that list, you can call the `getEndpointDowntime()` operation on the `GossiperMBean` to determine how long a given node has been down. The downtime is measured from the perspective of the node whose MBean you're inspecting, and the value resets when the node comes back online. Cassandra uses this operation internally to know how long it can wait to discard hints.

The `getCurrentGenerationNumber()` operation returns the generation number associated with a specific node. The generation number is included in gossip messages exchanged between nodes and is used to distinguish the current state of a node from the state prior to a restart. The generation number remains the same while the node is alive and is incremented each time the node restarts. It's maintained by the `Gossiper` using a timestamp.

The `assassinateEndpoint()` operation attempts to remove a node from the ring by telling the other nodes that the node has been permanently removed, similar to the concept of &ldquo;character assassination&rdquo; in human gossip. Assassinating a node is a maintenance step of last resort when a node cannot be removed from the cluster normally. This operation is used by the `nodetool assassinate` command.

[[failure_detector_mbean]]
===== Failure Detector MBean

The `org.apache.cassandra.gms.FailureDetectorMBean` provides attributes describing the states and Phi scores of other nodes, as well as the Phi conviction threshold.

[[snitch_mbeans]]
===== Snitch MBeans

Cassandra provides two MBeans to monitor and configure behavior of the snitch. The `org.apache.cassandra.locator.EndpointSnitchInfoMBean` provides the name of the rack and data center for a given host, as well as the name of the snitch in use.

If you're using the `DynamicEndpointSnitch`, the `org.apache.cassandra.locator.DynamicEndpointSnitchMBean` is registered. This MBean exposes the ability to reset the badness threshold used by the snitch to determine when to change its preferred replica for a token range, as well as allowing you to see the scores for various nodes.

[[stream_manager_mbean]]
===== Stream Manager MBean

The `org.apache.cassandra.streaming.StreamManagerMBean` allows us to see the SSTable streaming activities that occur between a node and its peers. There are two basic ideas here: a stream source and a stream destination. Each node can stream its data to another node in order to perform load balancing, and the `StreamManager` class supports these operations. The `StreamManagerMBean` gives a necessary view into the data that is moving between nodes in the cluster.

The `StreamManagerMBean` supports two modes of operation. The `getCurrentStreams()` operation provides a snapshot of the current incoming and outgoing streams, and the MBean also publishes notifications associated with stream state changes, such as initialization, completion, or failure. You can subscribe to these notifications in your JMX client in order to watch the streaming operations as they occur.

So in conjunction with the `StorageServiceMBean`, if you're concerned that a node is not receiving data as it should, or that a node is unbalanced or even down, these two MBeans working together can give you very rich insight into exactly what's happening in your cluster.

[[messaging_service_mbean]]
===== Messaging Service MBean

As you learned in <<the_cassandra_architecture>>, the `org.apache.cassandra.net.MessagingService` manages messages to and from other nodes other than streaming. The `MessagingServiceMBean` exposes attributes that include data about pending and dropped messages, as well as operations to manage backpressure.

[[internal_mbeans]]
==== Internal MBeans
The final MBeans we'll consider describe internal operations of the Cassandra node, including threading, garbage collection, security, and exposing metrics.

[[thread_pool_mbeans]]
===== Thread Pool MBeans

Cassandra's thread pools are implemented via the `JMXEnabledThreadPoolExecutor` and `JMXConfigurableThreadPoolExecutor` classes in the `org.apache.cassandra.concurrent` package. The MBeans for each stage implement the `JMXEnabledThreadPoolExecutorMBean` and `JMXConfigurableThreadPoolExecutorMBean` interfaces, respectively, which allow you to view and configure the number of core threads in each thread pool as well as the maximum number of threads. The MBeans for each type of thread pool appear under the `org.apache.cassandra.internal` domain to JMX clients.

[[garbage_collection_mbeans]]
===== Garbage Collection MBeans

The JVM's garbage collection processing can impact tail latencies if not tuned properly, so it's important to monitor its performance, as you'll see in <<performance_tuning>>. The `GCInspectorMXBean` appears in the `org.apache.cassandra.service` domain. It exposes the operation `getAndResetStats()` which retrieves and then resets garbage collection metrics that Cassandra collects on its JVM, which is used by the `nodetool gcstats` command. It also exposes attributes that control the thresholds at which `INFO` and `WARN` logging messages are generated for long garbage collection pauses.

[[security_mbeans]]
===== Security MBeans

The `org.apache.cassandra.auth` domain defines the `AuthCacheMBean`, which exposes operations used to configure how Cassandra caches client authentication records. We'll discuss this MBean in <<security>>.

[[metrics_mbeans]]
===== Metrics MBeans
The ability to access metrics related to application performance, health, and key activities has become an essential tool for maintaining web-scale applications. Fortunately, Cassandra collects a wide range of metrics on its own activities to help you understand the behavior. JMX supports several different styles of metrics, including counters, gauges, meters, histograms, and timers.

To make its metrics accessible via JMX, Cassandra uses http://metrics.dropwizard.io[the Dropwizard Metrics open source Java library]. Cassandra uses the `org.apache.cassandra.metrics.CassandraMetricsRegistry` to register its metrics with the Dropwizard Metrics library, which in turn exposes them as MBeans in the `org.apache.cassandra.metrics` domain. You'll see in <<metrics>> a summary of the specific metrics that Cassandra reports and learn how these can be exposed to metrics aggregation frameworks.You've already explored a few of the commands offered by `nodetool` in previous chapters, but let's take this opportunity to get properly acquainted.

`nodetool` ships with Cassandra and can be found in _&lt;cassandra-home&gt;/bin_. This is a command-line program that offers a rich array of ways to look at your cluster, understand its activity, and modify it. `nodetool` lets you get statistics about the cluster, see the ranges each node maintains, move data from one node to another, decommission a node, and even repair a node that's having trouble.

Behind the scenes, `nodetool` uses JMX to access the MBeans described above using a helper class called `org.apache.cassandra.tools.NodeProbe`. The `NodeProbe` class connects to the JMX agent at a specified node by its IP address and JMX port, locates MBeans, retrieves their data, and invokes their operations. The `NodeToolCmd` class in the same package is an abstract class which is extended by each `nodetool` command to provide access to administrative functionality in an interactive command-line interface.

`nodetool` uses the same environment settings as the Cassandra daemon: _bin/cassandra.in.sh_ and _conf/cassandra-env.sh_ on Unix (or _bin/cassandra.in.bat_ and _conf/cassandra-env.ps1_ on Windows). The logging settings are found in the _conf/logbacktools.xml_ file; these work the same way as the Cassandra daemon logging settings found in _conf/logback.xml_.

Starting `nodetool` is a breeze. Just open a terminal, navigate to _&lt;cassandra-home&gt;_, and enter the following command:

----
$ bin/nodetool help
----

This causes the program to print a list of available commands, several of which we will cover momentarily. Running `nodetool` with no arguments is equivalent to the `help` command. You can also execute help with the name of a specific command to get additional details.

[NOTE]
.Connecting to a Specific Node
====
With the exception of the `help` command, `nodetool` must connect to a Cassandra node in order to access information about that node or the cluster as a whole.

You can use the `-h` option to identify the IP address of the node to connect to with `nodetool`. If no IP address is specified, the tool attempts to connect to the default port on the local machine.

If you have a `ccm` cluster available, as discussed in <<configuring_and_deploying>>, you can run `nodetool` commands against specific nodes, for example:
----
ccm node1 nodetool help
----

To get more interesting statistics from a cluster as you try out the commands in this chapter yourself, you might want to run your own instance of the Reservation Service introduced in <<application_design>> and <<application_development>>.
====

// TODO: need to describe somewhere how to run the reservation service with data

[[getting_cluster_information]]
==== Getting Cluster Information

You can get a variety of information about the cluster and its nodes, which we look at in this section. You can get basic information on an individual node or on all the nodes participating in a ring.

[[describecluster]]
===== describecluster

The `describecluster` command prints out basic information about the cluster, including the name, snitch, and partitioner. For example, here's a portion of the output when run against the cluster created for the Reservation Service using `ccm`:

----
$ ccm node1 nodetool describecluster

Cluster Information:
	Name: reservation_service
	Snitch: org.apache.cassandra.locator.SimpleSnitch
	DynamicEndPointSnitch: enabled
	Partitioner: org.apache.cassandra.dht.Murmur3Partitioner
	Schema versions:
		2b88dbfd-6e40-3ef1-af11-d88b6dff2c3b: [127.0.0.4, 127.0.0.3,
  127.0.0.2, 127.0.0.1]
...
----

We've shortened the output a bit for brevity. The +Schema versions+ portion of the output is especially important for identifying any disagreements in table definitions, or schema, between nodes. While Cassandra propagates schema changes through a cluster, any differences are typically resolved quickly, so any lingering schema differences usually correspond to a node that is down or unreachable and needs to be restarted, which you should be able to confirm via the summary statistics on nodes that are also printed out.

[[status]]
===== status

A more direct way to identify the nodes in your cluster and what state they're in, is to use the `status` command:

----
$ ccm node1 nodetool status

Datacenter: datacenter1
=======================
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address    Load        Tokens  Owns (effective)  Host ID      Rack
UN  127.0.0.1  251.77 KiB  256     48.7%             d23716cb...  rack1
UN  127.0.0.2  250.28 KiB  256     50.0%             635f2ab7...  rack1
UN  127.0.0.3  250.47 KiB  256     53.6%             a1cd5663...  rack1
UN  127.0.0.4  403.46 KiB  256     47.7%             b493769e...  rack1
----

The status is organized by data center and rack. Each node's status is identified by a two-character code: the first character indicates whether the node is up (currently available and ready for queries) or down, and the second character indicates the state or operational mode of the node. The `load` column represents the byte count of the data each node is holding. The `owns` column indidates the effective percentage of the token range owned by the node, taking replication into account.

[[info]]
===== info

The `info` command tells `nodetool` to connect with a single node and get basic data about its current state. Just pass it the address of the node you want info for:

----
$ ccm node2 nodetool info

ID                     : 635f2ab7-e81a-423b-a566-674d8010c819
Gossip active          : true
Native Transport active: true
Load                   : 250.28 KiB
Generation No          : 1574894395
Uptime (seconds)       : 146423
Heap Memory (MB)       : 191.69 / 495.00
Off Heap Memory (MB)   : 0.00
Data Center            : datacenter1
Rack                   : rack1
Exceptions             : 0
Key Cache              : entries 10, size 896 bytes, capacity 24 MiB,
                         32 hits, 44 requests, 0.727 recent hit rate,
                         14400 save period in seconds
Row Cache              : entries 0, size 0 bytes, capacity 0 bytes,
                         0 hits, 0 requests, NaN recent hit rate,
                         0 save period in seconds
Counter Cache          : entries 0, size 0 bytes, capacity 12 MiB,
                         0 hits, 0 requests, NaN recent hit rate,
                         7200 save period in seconds
Chunk Cache            : entries 16, size 256 KiB, capacity 91 MiB,
                         772 misses, 841 requests, 0.082 recent hit rate,
                         NaN microseconds miss latency
Percent Repaired       : 100.0%
Token                  : (invoke with -T/--tokens to see all 256 tokens)
----

The information reported includes the memory and disk usage (`Load`) of the node and the status of various services offered by Cassandra. You can also check the status of individual services with the `nodetool` commands `statusgossip`, `statusbinary`, and `statushandoff` (note that handoff status is not part of `info`).

[[ring]]
===== ring

To determine what nodes are in your ring and what state they're in, use the `ring` command on `nodetool`, like this:

----
$ Datacenter: datacenter1
==========
Address    Rack   Status  State   Load        Owns     Token
                                                       9218490134647118760
127.0.0.1  rack1  Up      Normal  251.77 KiB  48.73%   -9166983985142207552
127.0.0.4  rack1  Up      Normal  403.46 KiB  47.68%   -9159867377343852899
127.0.0.2  rack1  Up      Normal  250.28 KiB  49.99%   -9159653278489176223
127.0.0.1  rack1  Up      Normal  251.77 KiB  48.73%   -9159520114055706114
...
----

This output is organized in terms of virtual nodes (vnodes). Here you see the IP addresses of all the nodes in the ring. In this case, there are three nodes, all of which are up (currently available and ready for queries). The load column represents the byte count of the data each node is holding. The output of the `describering` command is similar but is organized around token ranges.

Other useful status commands provided by `nodetool` include:

* The `getLoggingLevels` and `setLoggingLevels` commands allow dynamic configuration of logging levels, using the Logback `JMXConfiguratorMBean` we discussed previously.

* The `gossipinfo` command prints the information this node disseminates about itself and has obtained from other nodes via gossip, while `failuredetector` provides the Phi failure detection value calculated for other nodes.

* The `version` command prints the version of Cassandra this node is running.

[[getting_statistics]]
==== Getting Statistics

`nodetool` also lets you gather statistics about the state of your server in the aggregate level as well as down to the level of specific keyspaces and tables. Two of the most frequently used commands are `tpstats` and `tablestats`, both of which we examine now.

[[using_tpstats]]
===== Using tpstats

The `tpstats` tool gives us information on the thread pools that Cassandra maintains. Cassandra is highly concurrent, and optimized for multiprocessor/multicore machines, so understanding the behavior and health of the thread pools is important to good Cassandra maintenance.

To find statistics on the thread pools, execute `nodetool` with the `tpstats` command:

----
$ bin/nodetool tpstats
ccm node1 nodetool tpstats

Pool Name           Active   Pending  Completed   Blocked  All time blocked
ReadStage                0         0        399         0                 0
MiscStage                0         0          0         0                 0
CompactionExecutor       0         0      95541         0                 0
MutationStage            0         0          0         0                 0
...

Message type   Dropped    Latency waiting in queue (micros)
                           50%       95%       99%       Max
READ_RSP             0    0.00      0.00      0.00      0.00
RANGE_REQ            0    0.00      0.00      0.00      0.00
PING_REQ             0    0.00      0.00      0.00      0.00
_SAMPLE              0    0.00      0.00      0.00      0.00
----

The top portion of the output presents data on tasks in each of Cassandra's thread pools. You can see directly how many operations are in what stage, and whether they are active, pending, or completed. For example, by reviewing the number of active tasks in the `MutationStage`, you can learn how many writes are in progress.

The bottom portion of the output indicates the number of dropped messages for the node. Dropped messages are an indicator of Cassandra's load shedding implementation, which each node uses to defend itself when it receives more requests than it can handle. For example, internode messages that are received by a node but not processed within the `rpc_timeout` are dropped, rather than processed, as the coordinator node will no longer be waiting for a response.

Seeing lots of zeros in the output for blocked tasks and dropped messages means that you either have very little activity on the server or that Cassandra is doing an exceptional job of keeping up with the load. Lots of nonzero values are indicative of situations where Cassandra is having a hard time keeping up, and may indicate a need for some of the techniques described in <<performance_tuning>>.

[[using_tablestats]]
===== Using tablestats

To see overview statistics for keyspaces and tables, you can use the `tablestats` command. You may also recognize this command from its previous name, `cfstats`. Here is sample output on the `reservations_by_confirmation` table:

----
$ ccm node1 nodetool tablestats reservation.reservations_by_confirmation

Total number of tables: 43
----------------
Keyspace : reservation
	Read Count: 0
	Read Latency: NaN ms
	Write Count: 0
	Write Latency: NaN ms
	Pending Flushes: 0
		Table: reservations_by_confirmation
		SSTable count: 0
		Old SSTable count: 0
		Space used (live): 0
		Space used (total): 0
		Space used by snapshots (total): 0
		Off heap memory used (total): 0
		SSTable Compression Ratio: -1.0
		Number of partitions (estimate): 0
		Memtable cell count: 0
		Memtable data size: 0
		Memtable off heap memory used: 0
		Memtable switch count: 0
		Local read count: 0
		Local read latency: NaN ms
		Local write count: 0
		Local write latency: NaN ms
		Pending flushes: 0
		Percent repaired: 100.0
		Bloom filter false positives: 0
		Bloom filter false ratio: 0.00000
		Bloom filter space used: 0
		Bloom filter off heap memory used: 0
		Index summary off heap memory used: 0
		Compression metadata off heap memory used: 0
		Compacted partition minimum bytes: 0
		Compacted partition maximum bytes: 0
		Compacted partition mean bytes: 0
		Average live cells per slice (last five minutes): NaN
		Maximum live cells per slice (last five minutes): 0
		Average tombstones per slice (last five minutes): NaN
		Maximum tombstones per slice (last five minutes): 0
		Dropped Mutations: 0
----

You can see the read and write latency, and total number of reads and writes. You can also see detailed information about Cassandra's internal structures for the table, including memtables, Bloom filters, and SSTables. You can get statistics for all the tables in a keyspace by specifying just the keyspace name, or specify no arguments to get statistics for all tables in the cluster.

[[virtual_tables]]
=== Virtual Tables

In the 4.0 release, Cassandra added a _virtual tables_ feature. Virtual tables are so named because they are not actual tables that are stored using Cassandra's typical write path, with data written to memtables and SSTables. Instead, these virtual tables are views that provide metadata about nodes and tables via standard CQL.
// https://issues.apache.org/jira/browse/CASSANDRA-7622

This metadata is available via two keyspaces which you may have noticed in earlier chapters when you used the `DESCRIBE KEYSPACES` command, called `system_views` and `system_virtual_schema`:

```````````````````
<pre xmlns="http://www.w3.org/1999/xhtml" data-type="programlisting">cqlsh&gt; DESCRIBE KEYSPACES;

reservation    system_traces  system_auth  system_distributed     <strong><code>system_views</code></strong>
system_schema  system       <strong><code>system_virtual_schema</code></strong></pre>
```````````````````

These two keyspaces contain virtual tables that provide different types of metadata. Before we look into them, here are a couple of important things you should know about virtual tables:

* You may not define your own virtual tables.
* The scope of virtual tables is the local node.
* When interacting with virtual tables through `cqlsh`, results will come from the node that `cqlsh` connected to, as you'll see next.
* Virtual tables are not persisted, so any statistics will be reset when the node restarts.

[[system_virtual_schema]]
==== System Virtual Schema
Let's look first at the tables in the `system_virtual_schema`:

----
cqlsh:system> USE system_virtual_schema;
cqlsh:system_virtual_schema> DESCRIBE TABLES;

keyspaces  columns  tables
----

If you examine the schema and contents of the `keyspaces` table, you'll see that the schema of this table is extremely simple—it's just a list of keyspace names.

----
cqlsh:system_virtual_schema> SELECT * FROM KEYSPACES;

 keyspace_name
-----------------------
           reservation
          system_views
 system_virtual_schema

(3 rows)
----

The design of the `tables` table is quite similar, consisting of `keyspace_name`, `table_name`, and `comment` columns, in which the primary key is `(keyspace_name, table_name)`.

The columns table is more interesting. We'll focus on a subset of the available columns:

----
cqlsh:system_virtual_schema> SELECT column_name, clustering_order, kind,
  position, type FROM columns WHERE keyspace_name = 'reservation' AND
  table_name = 'reservations_by_hotel_date';

 column_name    | clustering_order | kind          | position | type
----------------+------------------+---------------+----------+----------
 confirm_number |             none |       regular |       -1 |     text
       end_date |             none |       regular |       -1 |     date
       guest_id |             none |       regular |       -1 |     uuid
       hotel_id |             none | partition_key |        0 |     text
    room_number |              asc |    clustering |        0 | smallint
     start_date |             none | partition_key |        1 |     date

(6 rows)
----

As you can see, this query provides enough data to describe the schema of a table, including the columns and primary key definition. Although it does not include the table options, the response is otherwise quite similar in content to the output of the +cqlsh+ `DESCRIBE` operations.

Interestingly, `cqlsh` traditionally scanned tables in the `system` keyspace to implement these operations, but is updated in the 4.0 release to use virtual tables.

[[system_views]]
==== System Views
The second keyspace containing virtual tables is the `system_views` keyspace. Let's get a list of the available views:

----
cqlsh:system_virtual_schema> SELECT * FROM tables WHERE
  keyspace_name = 'system_views';

 keyspace_name | table_name                | comment
---------------+---------------------------+-----------------------------
  system_views |                    caches |               system caches
  system_views |                   clients | currently connected clients
  system_views |  coordinator_read_latency |
  system_views |  coordinator_scan_latency |
  system_views | coordinator_write_latency |
  system_views |                disk_usage |
  system_views |         internode_inbound |
  system_views |        internode_outbound |
  system_views |        local_read_latency |
  system_views |        local_scan_latency |
  system_views |       local_write_latency |
  system_views |        max_partition_size |
  system_views |             rows_per_read |
  system_views |                  settings |            current settings
  system_views |             sstable_tasks |       current sstable tasks
  system_views |              thread_pools |
  system_views |       tombstones_per_read |

(17 rows)
----

As you can see, there is a mix of tables that provide latency histograms for reads and writes to local storage, and for when this node is acting as a coordinator.

The `max_partition_size` and `tombstones_per_read` tables are particularly useful in helping to identify some of the situations that lead to poor performance in Cassandra clusters, which we'll address in <<maintenance>>.

The `disk_usage` view provides the `storage` expressed in mebibytes (1,048,576 bytes). Again, remember this is how much storage there is for each table on that individual node. Related to this is the `max_partition_size`, which can be useful in determining if a node is affected by a wide partition. You'll learn more about how to detect and address these in <<performance_tuning>>.

Let's look a bit more closely at a couple of these tables. First, let's have a look at a few of the columns in the `clients` table:

----
cqlsh:system_virtual_schema> USE system_views;
cqlsh:system_views> SELECT address, port, hostname, request_count
  FROM clients;

 address   | port  | hostname  | request_count
-----------+-------+-----------+--------------
 127.0.0.1 | 50631 | localhost |           261
 127.0.0.1 | 50632 | localhost |           281
----

As you can see, this table provides information about each client with an active connection to the node, including its location and number of requests. Other columns not shown here provide information about the client's identity and encryption settings, and the protocol version in use. This information is useful to make sure the list of clients and their level of usage is in line with what you expect for your application.

Another useful table is `settings`. This allows you to see the values of configurable parameters for the node set via the _cassandra.yaml_ file or subsequently modified via JMX:

----
cqlsh:system_views> SELECT * FROM settings LIMIT 10;

 name                                         | value
----------------------------------------------+----------------------
                 allocate_tokens_for_keyspace |                  null
 allocate_tokens_for_local_replication_factor |                  null
         audit_logging_options_audit_logs_dir |      /var/logs/audit/
                audit_logging_options_enabled |                 false
    audit_logging_options_excluded_categories |
     audit_logging_options_excluded_keyspaces | system,system_schema,
                                              | system_virtual_schema
         audit_logging_options_excluded_users |
    audit_logging_options_included_categories |
     audit_logging_options_included_keyspaces |
         audit_logging_options_included_users |

(10 rows)
----

You'll notice that much of this same information could be accessed via various `nodetool` commands. However, the value of virtual tables is that they may be accessed through any client using the CQL native protocol, including applications you write using the DataStax Java Drivers. Of course, some of these values you may not wish to allow your clients access to; we'll discuss how to secure access to keyspaces and tables in <<security>>.

[NOTE]
.More Virtual Table Functionality
====
While the 4.0 release provides a very useful set of virtual tables, the Cassandra community has proposed several additional virtual tables that may be added in future releases, which you can find in the Cassandra Jira:

* Set configuration values on the `settings` table ((https://issues.apache.org/jira/browse/CASSANDRA-15254)[CASSANDRA-15254])
* Hints metadata ((https://issues.apache.org/jira/browse/CASSANDRA-14795)[CASSANDRA-14795])
* Additional table metrics ((https://issues.apache.org/jira/browse/CASSANDRA-14572)[CASSANDRA-14572])
* Access to individual partition sizes ((https://issues.apache.org/jira/browse/CASSANDRA-12367)[CASSANDRA-12367])
* Get a listing of current running queries ((https://issues.apache.org/jira/browse/CASSANDRA-15241)[CASSANDRA-15241])
* Repair status ((https://issues.apache.org/jira/browse/CASSANDRA-15399)[CASSANDRA-15399])

We expect that the data available via virtual tables will eventually catch up with JMX, and even surpass it in some areas.
====

If you're interested in the implementation of virtual tables, you can find the code in the `org.apache.cassandra.db.virtual` package. For more detail on using virtual tables, see Alexander Dejanovski's blog post, (https://thelastpickle.com/blog/2019/03/08/virtual-tables-in-cassandra-4_0.html)["Virtual tables are coming in Cassandra 4.0"].

[[metrics]]
=== Metrics

As we mentioned at the start of this chapter, metrics are a vital component of the observability of the system. It's important to have access to metrics at the OS, JVM, and application level. The metrics Cassandra reports at the application level include:

* _Buffer pool metrics_ describing Cassandra's use of memory

* _CQL metrics_, including the number of prepared and regular statement executions

* _Cache metrics_ for key, row, and counter caches, such as the number of entries versus capacity, as well as hit and miss rates

* _Client metrics_, including the number of connected clients, and information about client requests such as latency, failures, and timeouts

* _Commit log metrics_, including the commit log size and statistics on pending and completed tasks

* _Compaction metrics_, including the total bytes compacted and statistics on pending and completed compactions

* _Connection metrics_ to each node in the cluster, including gossip

* _Dropped message metrics_ that are used as part of `nodetool tpstats`

* _Read repair metrics_ describing the number of background versus blocking read repairs performed over time

* _Storage metrics_, including counts of hints in progress and total hints

* _Streaming metrics_, including the total incoming and outgoing bytes of data streamed to other nodes in the cluster

* _Thread pool metrics_, including active, completed, and blocked tasks for each thread pool

* _Table metrics_, including caches, memtables, SSTables, and Bloom filter usage, and the latency of various read and write operations, reported at 1-, 5-, and 15-minute intervals

* _Keyspace metrics_ that aggregate the metrics for the tables in each keyspace

Many of these metrics are used by `nodetool` commands such as `tpstats`, `tablehistograms`, and `proxyhistograms`. For example, `tpstats` is simply a presentation of the thread pool and dropped message metrics.

[NOTE]
.Resetting Metrics
====
Note that in Cassandra releases through 4.0, the metrics reported are lifetime metrics since the node was started. To reset the metrics on a node, you have to restart it. The Jira issue https://issues.apache.org/jira/browse/CASSANDRA-8433[CASSANDRA-8433] requests the ability to reset the metrics via JMX and `nodetool`.

====

[[metrics_aggregation]]
.Metrics Aggregation
****

You've already read how Cassandra exposes metrics via JMX and Dropwizard, and how you can view some of these metrics via tools, including `nodetool` and `cqlsh` (via virtual tables). These tools are a great help for looking at the state of one node at a time. Cassandra's metrics can also fit into a broader observability strategy for your applications.

If you've had experience building cloud applications, you may be familiar with metrics aggregation frameworks such as Prometheus and metrics visualization tools such as Grafana. There's a https://github.com/soccerties/cassandra-monitoring[simple integration] available on GitHub that you can use to aggregate Cassandra and operating system metrics from across your cluster. This repository provides configuration files for running Prometheus and Grafana in Docker, and instructions for how to install agents that will expose metrics from your nodes to Prometheus. There are four built-in Grafana dashboards which provide useful sets of metrics to observe:

Cpass:[*] Cluster Overview:: 
This dashboard provides a top-level summary of the health of your cluster, highlighting cluster size, total data stored, node compute data in terms of CPU, memory, disk, and network, and Cassandra statistics.
Cpass:[*] Cluster Metrics::
This dashboard provides a deeper look into Cassandra-specific metrics, including read and write load and latencies, and information about active, pending, and blocked tasks per node, as shown in <<grafana_metrics>>.
Cpass:[*] Table Metrics::
This dashboard allows you to slice read and write metrics by keyspace and table to get a more fine-grained view.
System Metrics::
This dashboard provides a deeper look into the compute metrics of nodes as collected from the host operating system.

[[grafana_metrics]]
.Cassandra metrics dashboard in Grafana
image::images/cdg3_1102.png[]

These dashboards enable you to assess the overall health of Cassandra clusters and get early indication of potential issues. Another powerful technique is to create dashboards that combine Cassandra cluster and application-level metrics such as those made available via the DataStax drivers, as you learned in <<application_development>>. This will give you a deeper understanding of how Cassandra and your application code interact to affect the overall performance and health of your system.
****

[[logging-id1]]
=== Logging
// http://cassandra.apache.org/doc/latest/troubleshooting/reading_logs.html
While you can learn a lot about the overall health of your cluster from metrics, logging provides a way to get more specific detail about what's happening in your database so that you can investigate and troubleshoot specific issues. Cassandra uses the Simple Logging Facade for Java (SLF4J) API for logging, with Logback as the implementation. SLF4J provides a facade over various logging frameworks such as Logback, Log4j, and Java's built-in logger (`java.util.logging`). You can learn more about Logback (http://logback.qos.ch/)[here]. Cassandra's default logging configuration is found in the file _&lt;cassandra-home&gt;/conf/logback.xml_.

The SLF4J API is built around the concepts of _loggers_ and _appenders_. Each class in a Java application has a dedicated logger, plus there are loggers for each level of the package hierarchy, as well as a root logger. This allows fine-grained control over logging; you can configure the log level for a particular class or any level in the package hierarchy, or even the root level. The API uses a progression of log levels: `ALL &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL &lt; OFF`. When you configure a log level for a logger, messages at that log level and greater will be output via appenders (which we'll introduce below). You can see how the logging level for Cassandra's classes is set in the _logback.xml_ file:

----
  <logger name="org.apache.cassandra" level="DEBUG"/>
----

Note that the root logger defaults to the `INFO` logging level, so that is the level at which all other classes will report.

An appender is responsible for taking generated log messages that match a provided filter and outputting them to some location. According to the default configuration found in _logback.xml_, Cassandra provides appenders for logging into three different files:

* The _system.log_ contains logging messages at the `INFO` logging level and greater. You've already seen some of the contents of the _system.log_ in <<configuring_and_deploying>> as you were starting and stopping a node, so you know that this log will contain information about nodes joining and leaving a cluster. It also contains information about schema changes.
* The _debug.log_ contains more detailed messages useful for debugging, incorporating the `DEBUG` log level and above. This log can be pretty noisy but provides a lot of useful information about internal activity within a node, including memtable flushing and compaction.
* The _gc.log_ contains messages related to the JVM's garbage collection. This is a standard Java garbage collection log file and is particularly useful for identifying long garbage collection pauses. We'll discuss garbage collection tuning in <<performance_tuning>>.

The default configuration also describes an appender for the console log, which you can access in the terminal window where you start Cassandra by setting the `-f` flag (to keep output visible in the foreground of the terminal window).

By default, Cassandra's log files are stored in the _logs_ directory under the Cassandra installation directory. If you want to change the location of the _logs_ directory, you can override this value using the `CASSANDRA_LOG_DIR` environment variable when starting Cassandra, or you can edit the _logback.xml_ file directly.

The default configuration does not pick up changes to the logging settings on a live node. You can ask Logback to rescan the configuration file once a minute, by setting properties in the _logback.xml_ file:

----
<configuration scan="true" scanPeriod="60 seconds">
----

You may also view the log levels on a running node through the `nodetool getlogginglevels` command, and override the log level for the logger at any level of the Java package and class hierarchy using `nodetool setlogginglevel`.

Other settings in the _logback.xml_ file support rolling log files. By default, the logs are configured to use the `SizeAndTimeBasedRollingPolicy`. Each log file will be rolled to an archive once it reaches a size of 50 MB or at midnight, whichever comes first, with a maximum of 5 GB across all system logs. For example, look at the configuration of the rolling policy for the _system.log_:

----
<rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
  <fileNamePattern>
    ${cassandra.logdir}/system.log.%d{yyyy-MM-dd}.%i.zip
  </fileNamePattern>
  <maxFileSize>50MB</maxFileSize>
  <maxHistory>7</maxHistory>
  <totalSizeCap>5GB</totalSizeCap>
</rollingPolicy>
----

Each log file archive is compressed in zip format and named according to the pattern described above, which will lead to files named _system.log.2020-05-30.0.zip_, _system.log.2020-05-30.1.zip_, and so on. These archived log files are kept for seven days by default. The default settings may well be suitable for development and production environments; just make sure you account for the storage that will be required in your planning.

[[examining_log_files]]
==== Examining Log Files

You can examine log files in order to determine things that are happening with your nodes. One of the most important tasks in monitoring Cassandra is to regularly check log files for statements at the `WARN` and `ERROR` log levels. Several of the conditions under which Cassandra generates `WARN` log messages are configurable via the _cassandra.yaml_ file:

* The `tombstone_warn_threshold` property sets the maximum number of tombstones that Cassandra will encounter on a read before generating a warning. This value defaults to 1000.
* The `batch_size_warn_threshold_in_kb` property sets the maximum size of the total data in a batch command, which is useful for detecting clients that might be trying to insert a quantity of data in a batch that will negatively impact the coordinator node performance. The default value is 5 kb.
* The `gc_warn_threshold_in_ms` property sets the maximum garbage collection pause that will cause a warning log. This defaults to 1000 ms (1 second), and the corresponding setting for `INFO` log messages `gc_log_threshold_in_ms` is set at 200 ms.

Here's an example of a message you might find in the logs for a query that encounters a large number of tombstones:

----
WARN  [main] 2020-04-08 14:30:45,111 ReadCommand.java:598 -
  Read 0 live rows and 3291 tombstone cells for query
  SELECT * FROM reservation.reservations_by_hotel_date
  (see tombstone_warn_threshold)
----

[NOTE]
.Log Aggregation and Distributed Tracing
====
As with the use of metrics aggregation, it's also frequently helpful to aggregate logs across multiple microservices and infrastructure components in order to analyze threads of related activity correlated by time. There are many commercial log aggregation solutions available, and the ELK stack consisting of Elasticsearch, Logstash, and Kibana is a popular combination of open source projects used for log aggregation and analysis.

An additional step beyond basic aggregation is the ability to perform distributed traces of calls throughout a system. This involves incorporating a correlation ID into metadata passed on remote calls or messages between services. The correlation ID is a unique identifier, typically assigned by a service at the entry point into the system. The correlation ID can be used as a search criteria through aggregated logs to identify work performed across a system associated with a particular request. You'll learn more about tracing with Cassandra in <<performance_tuning>>.

====

You can also observe the regular operation of the cluster through the log files. For example, you could connect to a node in a cluster started using `ccm`, as described in <<configuring_and_deploying>>, and write a simple value to the database using `cqlsh`:

----
$ ccm node2 cqlsh
cqlsh> INSERT INTO reservation.reservations_by_confirmation
  (confirm_number, hotel_id, start_date, end_date, room_number,
  guest_id) VALUES ('RS2G0Z', 'NY456', '2020-06-08', '2020-06-10',
  111, 1b4d86f4-ccff-4256-a63d-45c905df2677);
----

If you execute this command, `cqlsh` will use `node2` as the coordinator, so you can check the logs for `node2`:

----
$ tail ~/.ccm/reservation_service/node2/logs/system.log
INFO  [Messaging-EventLoop-3-5] 2019-12-07 16:00:45,542
  OutboundConnection.java:1135 - 127.0.0.2:7000(127.0.0.3:7000)->
  127.0.0.3:7000(127.0.0.3:62706)-SMALL_MESSAGES-627a8d80 successfully
   connected, version = 12, framing = CRC, encryption = disabled
INFO  [Messaging-EventLoop-3-10] 2019-12-07 16:00:45,545
  OutboundConnection.java:1135 - 127.0.0.2:7000(127.0.0.4:7000)->
  127.0.0.4:7000(127.0.0.4:62707)-SMALL_MESSAGES-5bc34c55 successfully
   connected, version = 12, framing = CRC, encryption = disabled
INFO  [Messaging-EventLoop-3-8] 2019-12-07 16:00:45,593
  InboundConnectionInitiator.java:450 - 127.0.0.1:7000(127.0.0.2:62710)->
  127.0.0.2:7000-SMALL_MESSAGES-9e9a00e9 connection established,
  version = 12, framing = CRC, encryption = disabled
INFO  [Messaging-EventLoop-3-7] 2019-12-07 16:00:45,593
  InboundConnectionInitiator.java:450 - 127.0.0.3:7000(127.0.0.2:62709)->
  127.0.0.2:7000-SMALL_MESSAGES-e037c87e connection established,
  version = 12, framing = CRC, encryption = disabled
----

This output shows connections initiated from `node2` to the other nodes in the cluster to write replicas, and the corresponding responses. If you examine the `debug.log`, you'll see similar information, but not the details of the specific query that was executed.

[[full_query_logging]]
==== Full Query Logging
If you want more detail on exact CQL query strings that are used by client applications, use the full query logging feature introduced in Cassandra 4.0. The full query log is a binary log designed to be extremely fast and add the minimum possible overhead to your queries. Full query logging is also useful for live traffic capture and replay.

To enable full query logging on a node, create a directory to hold the logs and then set the `full_query_logging_options` in the _cassandra.yaml_ file to point to the directory:

----
full_query_logging_options:
  log_dir: /var/tmp/fql_logs
----

Other configuration options allow you to control how often the log is rolled over to a new file (hourly by default), specify a command used to archive the log files, and set a limit for full query logs. The full query log will not be enabled until you run the `nodetool enablefullquerylog` command.

Cassandra provides a tool to read the logs under the _tools/bin/fqltool_ directory. Here's an example of what the output looks like after running some simple queries:

----
$ tools/bin/fqltool dump /var/tmp/fql_logs
Type: single-query
Query start time: 1575842591188
Protocol version: 4
Generated timestamp:-9223372036854775808
Generated nowInSeconds:1575842591
Query: INSERT INTO reservation.reservations_by_confirmation
  (confirm_number, hotel_id, start_date, end_date, room_number,
  guest_id) VALUES ('RS2G0Z', 'NY456', '2020-06-08', '2020-06-10', 111,
  1b4d86f4-ccff-4256-a63d-45c905df2677);
Values:

Type: single-query
Query start time: 1575842597849
Protocol version: 4
Generated timestamp:-9223372036854775808
Generated nowInSeconds:1575842597
Query: SELECT * FROM reservation.reservations_by_confirmation ;
Values:
----

Once you're done collecting full query logs, run the `nodetool disablefullquerylog` command.

[[summary-id11]]
=== Summary

In this chapter, you learned ways you can monitor and manage your Cassandra cluster. In particular, you learned the rich variety of operations Cassandra makes available via JMX to the MBean server. You also learned how to use `nodetool`, virtual tables, metrics, and logs to view what's happening in your Cassandra cluster. You are now ready to learn how to perform routine maintenance tasks to help keep your Cassandra cluster healthy.

