[[application_design]]
== Designing Applications with Cassandra

In the previous chapters you learned how Cassandra represents data, how to create Cassandra data models, and how Cassandra's architecture works to distribute data across a cluster so that you can access it quickly and reliably. Now itâ€™s time to take this knowledge and start to apply it in the context of real-world application design.

[[hotel_application_design]]
=== Hotel Application Design

Let's return to the hotel domain you began working with in <<data_modeling>>. Imagine that you've been asked to develop an application that leverages the Cassandra data models you created to represent hotels, their room availability, and reservations.

How will you get from a data model to the application? After all, data models don't exist in a vacuum. There must be software applications responsible for writing and reading data from the tables that you design. While you could take many architectural approaches to developing such an application, we'll focus in this chapter on the microservice architectural style.

[[microservice_architecture]]
==== Cassandra and Microservice Architecture

Over the past several years, the microservice architectural style has been foundational to the discipline of cloud-native applications. As a database designed for the cloud from the ground up, Cassandra is a natural fit for cloud-native applications.

We don't intend to provide a full discussion of the benefits of a microservice architecture here, but will reference a subset of the principles introduced in Sam Newman's book http://shop.oreilly.com/product/0636920033158.do[_Building Microservices_](O'Reilly), an excellent source on this topic.

Encapsulation::
_Encapsulation_ could also be phrased as "services that are focused on doing one thing well" or the "single responsibility principle."
+
By contrast, in many enterprises the database serves as a central integration point. An application might expose interfaces to other applications such as remote procedure call (RPC) or messaging interfaces, but its also common for one application to access another application's database directly, which violates encapsulation and produces dependencies between applications that can be difficult to isolate and debug (see <<integration_by_database>>).
+
[[integration_by_database]]
.Integration by database contrasted with microservices
image::images/cdg3_0701.png[]

Autonomy::
In a microservice architecture, _autonomy_ refers to the ability to independently deploy each microservice without dependence on any other microservices. This flexibility has significant advantages in allowing you to independently evolve portions of a deployed application without downtime, gradually introducing new versions of a service and minimizing the risk of these deployments.
+
Another implication of autonomy is that each microservice can have its own data store using the most appropriate technology for that service. We'll examine this flexibility in more detail in <<polyglot_persistence>>.

Scalability::
Microservice architecture provides a lot of flexibility by giving you the ability to run more or fewer instances of a service dynamically according to demand. This allows you to scale different aspects of an application independently.
+
For example, in a hotel domain there is a large disparity between _shopping_ (the amount of traffic devoted to looking for hotel rooms) and _booking_ (the much lower level of traffic associated with customers actually committing to a reservation). For this reason, you might expect to scale the services associated with hotel and inventory data to a higher degree than the services associated with storing reservations.


==== Microservice Architecture for a Hotel Application
To create a microservice architecture for the hotel application, you'll need to identify services, their interfaces, and how they interact. Although it was written well before microservices became popular, Eric Evans' book _Domain-Driven Design_(Addison-Wesley Professional) has proven to be a useful reference. One of the key principles Evans articulates is beginning with a domain model and identifying bounded contexts. This process has become a widely recommended approach for identifying microservices.

In <<architecture_design_artifacts>>, you can see some of the key architecture and design artifacts that are often produced when building new applications. Rather than a strict workflow, these are presented in an approximate order. The influences between these artifacts are sometimes sequential or _waterfall_ style, but are more often iterative in nature as designs are refined.

[[architecture_design_artifacts]]
.Artifacts produced by architectural and design processes
image::images/cdg3_0702.png[]

Use cases and access patterns are user experience (UX) design artifacts that also influence the data modeling and software architecture processes. We discussed the special role of access patterns in Cassandra data modeling in <<data_modeling>>, so let's focus here on the interactions between data modeling and software architecture.

To define a microservice architecture, let's use a process that complements the data modeling processes you've already learned. As you begin to identify entities as part of a conceptual data modeling phase, you can begin to identify bounded contexts that represent groupings of related entities.  As you progress into logical data modeling, you'll refine the bounded contexts in order to identify specific services that will be responsible for each table (or group of related, denormalized tables). During the final stage of the design process, you confirm the design of each service, the selection of database, the physical data models, and actual database schema.

==== Identifying Bounded Contexts
Let's see how this high-level process works in practice for your hotel application. Reusing the conceptual data model from <<data_modeling>>, you might choose to identify a Hotel Domain encompassing the information about hotels, their rooms, and availability, and a Reservation Domain to include information about reservations and guests, as shown in <<identifying_bounded_contexts>>. These happen to correspond to the keyspaces identified in your initial data model.

[[identifying_bounded_contexts]]
.Identifying bounded contexts for a hotel application
image::images/cdg3_0703.png[]

==== Identifying Services
The next step is to formalize the bounded contexts you've identified into specific services that will own specific tables within your logical data model. For example, the Hotel Domain identified previously might decompose into separate services focused on hotels, points of interest, and inventory availability, as shown in <<service_identification_hotel>>.

[[service_identification_hotel]]
.Identifying services for hotel data
image::images/cdg3_0704.png[]

There are multiple possible designs, but a good general design principle is to assign tables that have a high degree of correspondence to the same service. In particular, when working with Cassandra, a natural approach is to assign denormalized tables representing the same basic data type to the same service.

Services should embody classic object-oriented principles of coupling and cohesion: there should be a high degree of cohesion or relatedness between tables owned by a service, and a low amount of coupling or dependence between contexts. The query arrows on your Chebotko diagrams are helpful here in identifying relationships between services, whether they are direct invocation dependencies, or data flows orchestrated through user interfaces or events.

Using the same principles as above, examine the tables in your logical data model within the Reservation Domain. You might identify a Reservation Service and a Guest Service, as shown in  <<service_identification_reservations>>. In many cases there will be a one-to-one relationship between bounded contexts and services, although with more complex domains there could be further decomposition into services.

[[service_identification_reservations]]
.Identifying services for reservation data
image::images/cdg3_0705.png[]

While the initial design did not specifically identify access patterns for guest data outside of navigating to guest information from a reservation, it's not a big stretch to imagine that your business stakeholders will at some point want to allow guests to create and manage accounts on your application.

[[designing_microservice_persistence]]
==== Designing Microservice Persistence
The final stage in the data modeling process consists of creating physical data models. This corresponds to the architectural tasks of designing services, including database-related design choices such as selecting a database and creating database schema.

[[polyglot_persistence]]
===== Polyglot Persistence

One of the benefits of microservice architecture is that each service is independently deployable. This gives you the ability to select a different database for each microservice, an approach known as _polyglot persistence_.

While you might be surprised to read this in a book on Cassandra, it is nonetheless true that Cassandra may not be the ideal backing store for every microservice, especially those that do not require the scalability that Cassandra offers.

Let's examine the services you've identified in the design of your hotel application to identify some options for polyglot persistence. We'll summarize these in <<polyglot_persistence_example>>.

[[polyglot_persistence_example]]
.Polyglot persistence example
[options="header"]
|===
|Service | Data characteristics | Database options

|Hotel Service
|Descriptive text about hotels and their amenities, changes infrequently
|Document database (i.e., MongoDB), Cassandra, or Elasticsearch/Solr for full text search

|Point of Interest Service
|Geographic locations and descriptions of points of interest
|Cassandra or other tabular databases supporting geospatial indexes such as DataStax Enterprise

|Inventory Service
|Counts of available rooms by date, large volume of reads and writes
|Cassandra or other tabular databases

|Reservation Service
|Rooms reserved on behalf of guests, lower volume of reads and writes than inventory
|Cassandra or other tabular databases

|Guest Service
|Guest identity and contact information, possible extension point for customer and fraud analytics systems
|Cassandra, graph databases

|===

You might make some of your selections with an eye to future extensibility and scalability of the system.

[[other_database_models]]
===== Representing other database models in CQL
Key-value models can be represented in Cassandra by treating the key as the partition key. The remaining data can be stored in a value column as a _text_ or _blob_ type. It's recommended not to  exceed 5 MB for a single value, so consider breaking up large documents into multiple rows.

Document models::
There are two primary approaches in which Cassandra can behave like a document database, one based on having a well-defined schema, and the other approximating a flexible schema approach. Both involve identifying primary key columns according to standard Cassandra data modeling practices discussed in <<data_modeling>>.
+
The flexible schema approach involves storing nonprimary key columns in a blob, as in the following table definition:
+
----
CREATE TABLE hotel.hotels_document (
    id text PRIMARY KEY,
    document text);
----
+
With this design, the `document` column could contain arbitrary descriptive data in JavaScript Object Notation (JSON) or some other format, which would be left to the application to interpret. This could be somewhat error prone and is not a very elegant solution.
+
A better approach is to use CQL support for reading and writing data in JSON format, introduced in Cassandra 2.2. For example, you could insert data into the `hotels` table with this query:
+
----
cqlsh:hotel> INSERT INTO hotels JSON '{ "id": "AZ123",
  "name": "Super Hotel Suites at WestWorld",
  "phone": "1-888-999-9999",
  "address": {
    "street": "10332 E. Bucking Bronco",
    "city": "Scottsdale",
    "state_or_province": "AZ",
    "postal_code": 85255
  }
}';
----
+
Similarly, you can request data in JSON format from a CQL query. The response will contain a single text field labeled `json` that includes the requested columnsâ€”in this case, all of them (note that no formatting is provided for the output):
+
----
cqlsh:hotel> SELECT JSON * FROM hotels WHERE id = 'AZ123';

 [json]
------------------------------------------------
{ "id": "AZ123", "name": "Super Hotel Suites at WestWorld",
"phone": "1-888-999-9999", "address": {
"street": "10332 E. Bucking Bronco", "city": "Scottsdale",
"state_or_province": "AZ", "postal_code": 85255 }
----
+
The `INSERT JSON` and `SELECT JSON` commands are particularly useful for web applications or other JavaScript applications that use JSON representations. While the ability to read and write data in JSON format does make Cassandra appear to behave more like a document database, remember that all of the referenced attributes must be defined in the table schema.

Graph models::
Graph data models are a powerful way of representing domains where the relationships between entities are as important or more important than the properties of the entities themselves. Common graph representations include _property graphs_. A property graph consists of vertexes that represent the entities in a domain, while edges represent the relationships between vertices and can be navigated in either direction. Both vertices and edges can have properties, hence the name property graph.
+
Property graphs between related entities can be represented on top of Cassandra using an approach in which each vertex type and edge type is stored in a dedicated table. To interact with the graph, applications use a graph query language such as Gremlin or Cypher. Graph databases provide a processing engine that interprets these queries and executes them, including data access to an underlying storage layer. DataStax Enterprise is an example of a database that provides a graph API with Cassandra as the underlying storage layer.Anyone who has built and maintained an application of significant size knows that change is inevitable. Business stakeholders come up with new requirements that cause you to extend systems.

For example, let's say your business stakeholder approaches you after your initial hotel data model to identify additional ways that customers should be able to search for hotels in your application. You might represent these as additional access patterns, such as searching for hotels by name, location, or amenities, as shown in <<additional_hotel_access_patterns>>.

[[additional_hotel_access_patterns]]
.Additional hotel access patterns
image::images/cdg3_0706.png[]

According to the principles you learned in <<data_modeling>>, your first thought might be to continue the practice of denormalization, creating new tables that will be able to support each of these access patterns, as shown in <<additional_hotel_tables>>.

[[additional_hotel_tables]]
.Additional hotel tables
image::images/cdg3_0707.png[]

At this point, you now have five different access patterns for hotel data, and it's reasonable to begin to ask how many denormalized tables is too many. The correct answer for your domain is going to depend on several factors, including the volume of reads and writes, and the amount of data. However let's assume in this case that you'd like to explore some other options besides just automatically adding new tables to your design.

Cassandra provides two mechanisms that you can use as alternatives to managing multiple denormalized tables: secondary indexes and materialized views.

[[secondary_indexes]]
==== Secondary Indexes

If you try to query on a column in a Cassandra table that is not part of the primary key, you'll soon realize that this is not allowed. For example, consider the `hotels` table, which uses the `id` as the primary key. Attempting to query by the hotel's `name` results in the following output:

----
cqlsh:hotel> SELECT * FROM hotels
  WHERE name = 'Super Hotel Suites at WestWorld';
InvalidRequest: Error from server: code=2200 [Invalid query] message=
  "Cannot execute this query as it might involve data filtering and
  thus may have unpredictable performance. If you want to execute this
  query despite the performance unpredictability, use ALLOW FILTERING"
----

As the error message instructs, you could override Cassandra's default behavior in order to force it to query based on this column using the `ALLOW FILTERING` keyword. However, the implication of such a query is that Cassandra would need to ask all of the nodes in the cluster to scan all stored SSTable files for hotels matching the provided name, because Cassandra has no indexing built on that particular column. This could yield some undesirable side effects on larger or more heavily loaded clusters, including query timeouts and additional processing load on your Cassandra nodes.

One way to address this situation without adding an additional table using the hotel's name as a primary key is to create a _secondary index_ for the `name` column. A secondary index is an index on a column that is not part of the primary key:

----
cqlsh:hotel> CREATE INDEX ON hotels ( name );
----

You can also give an optional name to the index with the syntax `CREATE INDEX &lt;name&gt; ON...`. If you don't specify a name, `cqlsh` creates a name automatically according to the form _&lt;table name&gt;_&lt;column name&gt;_idx_. For example, you can learn the name of the index you just created using `DESCRIBE KEYSPACE`:

```````````````````
<pre xmlns="http://www.w3.org/1999/xhtml" data-type="programlisting">cqlsh:hotel&gt; DESCRIBE KEYSPACE;
...
CREATE INDEX <strong><code>hotels_name_idx</code></strong> ON hotel.hotels (name);</pre>
```````````````````

Now that you've created the index, your query will work as expected:

[listing]
....
cqlsh:hotel> SELECT id, name FROM hotels
  WHERE name = 'Super Hotel Suites at WestWorld';

 id    | name
-------+---------------------------------
 AZ123 | Super Hotel Suites at WestWorld

(1 rows)
....

You're not limited just to indexes based only on simple type columns. It's also possible to create indexes that are based on user-defined types or values stored in collections. For example, you might wish to be able to search based on the `address` column (based on the `address` UDT) or the `pois` column (a `set` of unique identifiers for points of interest):

----
cqlsh:hotel> CREATE INDEX ON hotels ( address );
cqlsh:hotel> CREATE INDEX ON hotels ( pois );
----

Note that for maps in particular, you have the option of indexing either the keys (via the syntax `KEYS(addresses)`), the values (which is the default), or both (in Cassandra 2.2 or later).

Now let's look at the resulting updates to the design of hotel tables, taking into account the creation of indexes on the `hotels` table as well as the service and updated keyspace assignments for each table, as shown in <<revised_hotel_physical_model>>. Note here the assignment of a keyspace per service, which we'll discuss more in depth in <<services_keyspaces_and_clusters>>.

[[revised_hotel_physical_model]]
.Revised hotel physical model
image::images/cdg3_0708.png[]

If you change your mind at a later time about these indexes, you can remove them using the `DROP INDEX` command:

----
cqlsh:hotels> DROP INDEX hotels_name_idx;
cqlsh:hotels> DROP INDEX hotels_address_idx;
cqlsh:hotels> DROP INDEX hotels_pois_idx;
----

[WARNING]
.Secondary Index Pitfalls
====
Because Cassandra partitions data across multiple nodes, each node must maintain its own copy of a secondary index based on the data stored in partitions it owns. For this reason, queries involving a secondary index typically involve more nodes, making them significantly more expensive.

Secondary indexes are not recommended for several specific cases:

* Columns with high cardinality. For example, indexing on the `hotel.address` column could be very expensive, as the vast majority of addresses are unique.

* Columns with very low data cardinality. For example, it would make little sense to index on the `user.title` column (from the `user` table in <<the_cassandra_query_language>>) in order to support a query for every &ldquo;Mrs.&rdquo; in the user table, as this would result in a massive row in the index.

* Columns that are frequently updated or deleted. Indexes built on these columns can generate errors if the amount of deleted data (tombstones) builds up more quickly than the compaction process can handle.

====

For optimal read performance, denormalized table designs or materialized views (which we'll discuss in the next section) are generally preferred to using secondary indexes. However, secondary indexes can be a useful way of supporting queries that were not considered in the initial data model design.

[[sasi_colon_a_new_secondary_index_impleme]]
.SASI: A New Secondary Index Implementation
****
The Cassandra 3.4 release introduced an experimental, alternative implementation of secondary indexes known as the SSTable Attached Secondary Index (SASI). SASI was developed by Apple and released as an open source implementation of Cassandra's secondary index API. As the name implies, SASI indexes are calculated and stored as part of each SSTable file, differing from the original Cassandra implementation, which stores indexes in separate, &ldquo;hidden&rdquo; tables.

The SASI implementation exists alongside traditional secondary indexes, and you can create a SASI index with the CQL `CREATE CUSTOM INDEX` command:

----
cqlsh:my_keyspace> CREATE CUSTOM INDEX hotel_name_sasi_idx
  ON hotels (name)
  USING 'org.apache.cassandra.index.sasi.SASIIndex'
  WITH OPTIONS= {'mode': 'CONTAINS'};
----

SASI indexes do offer functionality beyond the traditional secondary index implementation, such as the ability to do inequality (greater than or less than) searches on indexed columns. You can also use the CQL `LIKE` keyword to do text searches against indexed columns. For example, you could use the following query to find hotels whose name contains the substring &ldquo;world&rdquo; (case insensitive):

[listing]
....
cqlsh:hotel> SELECT id, name FROM hotels
  WHERE name LIKE '%world%';

 id    | name
-------+---------------------------------
 AZ123 | Super Hotel Suites at WestWorld

(1 rows)
....

While SASI indexes do perform better than traditional indexes by eliminating the need to read from additional tables, they still require reads from a greater number of nodes than a denormalized design.Materialized views were introduced to help address some of the shortcomings of secondary indexes discussed above. Creating indexes on columns with high cardinality tends to result in poor performance, because most or all of the nodes in the ring are queried.

Materialized views address this problem by storing preconfigured views that support queries. Each materialized view supports queries based on a single column which is not part of the original primary key. Materialized views simplify application development: instead of the application having to keep multiple denormalized tables in sync, Cassandra takes on the responsibility of updating views in order to keep them consistent with the base table.

Materialized views incur a performance impact on writes to the base table because some reads are required to maintain this consistency. However, materialized views demonstrate more efficient performance compared to managing denormalized tables in application clients. Internally, materialized view updates are implemented using batching, which we will discuss in <<writing_and_reading_data>>.

As you work with physical data model designs, you'll want to consider whether to manage the denormalization manually or use Cassandra's materialized view capability.

The design shown for the `reservation` keyspace in <<reservation_physical_model>> uses both approaches. The `reservations_by_hotel_date` and `reservations_by_guest` are represented as regular tables, and `reservations_by_confirmation` as a materialized view on the `reservations_by_hotel_date` table. Let's discuss the reasoning behind this design choice momentarily.

Similar to secondary indexes, materialized views are created on existing tables. To understand the syntax and constraints associated with materialized views, let's take a look at a CQL command that creates the `reservations_by_confirmation` table from the reservation physical model as a materialized view:

```````````````````
<pre xmlns="http://www.w3.org/1999/xhtml" data-type="programlisting">cqlsh&gt; <strong><code>CREATE MATERIALIZED VIEW</code></strong> reservation.reservations_by_confirmation
  <strong><code>AS SELECT</code></strong> *
  <strong><code>FROM</code></strong> reservation.reservations_by_hotel_date
  <strong><code>WHERE</code></strong> confirm_number IS NOT NULL and hotel_id IS NOT NULL and
    start_date IS NOT NULL and room_number IS NOT NULL
  <strong><code>PRIMARY KEY</code></strong> (confirm_number, hotel_id, start_date, room_number);</pre>
```````````````````

The order of the clauses in the `CREATE MATERIALIZED VIEW` command can appear somewhat inverted, so let's walk through these clauses in an order that is a bit easier to process.

The first parameter after the command is the name of the materialized viewâ€”in this case, `reservations_by_confirmation`. The `FROM` clause identifies the base table for the materialized view, `reservations_by_hotel_date`.

The `PRIMARY KEY` clause identifies the primary key for the materialized view, which must include all of the columns in the primary key of the base table. This restriction keeps Cassandra from collapsing multiple rows in the base table into a single row in the materialized view, which would greatly increase the complexity of managing updates.

The grouping of the primary key columns uses the same syntax as an ordinary table. The most common usage is to place the additional column first as the partition key, followed by the base table primary key columns, used as clustering columns for purposes of the materialized view.

The `WHERE` clause provides support for filtering. Note that a filter must be specified for every primary key column of the materialized view, even if it is as simple as designating that the value `IS NOT NULL`.

The `AS SELECT` clause identifies the columns from the base table that you want your materialized view to contain. You can reference individual columns, but in this case the wildcard `*` indicates that all columns will be part of the view.

[NOTE]
.Enhanced Materialized View Capabilities
====
The initial implementation of materialized views in the 3.0 release has some limitations on the selection of primary key columns and filters. There are several Jira issues in progress to add capabilities, such as multiple nonprimary key columns in materialized view primary keys, (https://issues.apache.org/jira/browse/CASSANDRA-9928)[CASSANDRA-9928], or using aggregates in materialized views, (https://issues.apache.org/jira/browse/CASSANDRA-9778)[CASSANDRA-9778]. If you're interested in these features, track the Jira issues to see when they will be included in a release.
====

Now that you have a better understanding of the design and use of materialized views, let's revisit the reservation physical design. Specifically, `reservations_by_confirmation` is a good candidate for implementation as a materialized view due to the high cardinality of the confirmation numbersâ€”after all, you can't get any higher cardinality than a unique value per reservation.

Here is the schema for this materialized view:

----

CREATE MATERIALIZED VIEW reservation.reservations_by_confirmation AS
SELECT * FROM reservation.reservations_by_hotel_date
WHERE confirm_number IS NOT NULL and hotel_id IS NOT NULL and
start_date IS NOT NULL and room_number IS NOT NULL
PRIMARY KEY (confirm_number, hotel_id, start_date, room_number);

----

An alternate design would be to use `reservations_by_confirmation` as the base table and `reservations_by_hotel_date` as a materialized view. However, because you cannot create a materialized view with multiple nonprimary key columns from the base table, this would have required you to designate either `hotel_id` or `date` as a clustering column in `reservations_by_confirmation`. Both designs might be acceptable based on the anticipated amount of data, but this should give some insight into the trade-offs you'll want to consider in selecting which of several denormalized table designs to use as the base table.

An updated physical data model reflecting the design of tables used by the Reservation Service and Guest Service is shown in <<revised_reservation_physical_model>>. In this view, the contents of the `reservations_by_confirmation` table are shown in italics to indicate it is a materialized view based on `reservations_by_hotel_date`.

[[revised_reservation_physical_model]]
.Revised Reservation physical model
image::images/cdg3_0709.png[]

[[experimental_features]]
.Experimental Features
****
Materialized views were a major selling point of the Cassandra 3.0 release and drove a number of significant design changes under the hood, such as the new storage engine we'll discuss in <<writing_and_reading_data>>. However, there were several rough edges and some corner cases that were not well handled in the initial implementation.

While there have been significant improvement on these issues in releases in the 3.X series, the Cassandra community has clarified the process for introducing new features entailing significant architectural change. These new features will now be designated as _experimental features_ and disabled by default. Enabling an experimental feature will require a change in the _cassandra.yaml_ file.

Other experimental features include the SASI indexes discussed above as well as transient replicas, a feature introduced in Cassandra 4.0 as a cost-saving measure for extremely large clusters. You'll learn more about transient replicas in <<writing_and_reading_data>>.

****

[[sample_microservice]]
=== Reservation Service: A Sample Microservice

So far, you've learned how a microservice architecture is a natural fit for using Cassandra, identified candidate services for a hotel application, and considered how service design might influence your Cassandra data models. The final subject to examine is the design of individual microservices.

[[design_choices]]
==== Design Choices for a Java Microservice
Let's narrow the focus to the design of a single service: the Reservation Service. As discussed above, the Reservation Service will be responsible for reading and writing data using the tables in the `reservation` keyspace.

A candidate design for a Java implementation of the Reservation Service using popular libraries and frameworks is shown in <<reservation_service_java_design>>. This implementation uses Apache Cassandra for its data storage via the DataStax Java Driver and the Spring Boot project for managing the service life cycle. It exposes a RESTful API documented via Swagger.

[[reservation_service_java_design]]
.Reservation Service Java design
image::images/cdg3_0710.png[]

The Reservation Service Java implementation can be found on GitHub at (https://github.com/jeffreyscarpenter/reservation-service)[]. The goal of this project is to provide a minimally functional implementation of a Java microservice using the DataStax Java Driver that can be used as a reference or starting point for other applications. We'll be referencing this source code in <<application_development>> as we examine the functionality provided by the various DataStax drivers.

[[deployment_and_integration_considerations]]
=== Deployment and Integration Considerations
As you proceed into implementation, there are a couple of factors you'll want to consider related to how the service will be deployed and integrated with other services and supporting infrastructure.

[[services_keyspaces_and_clusters]]
==== Services, Keyspaces, and Clusters
First, you'll want to consider the relationship of services to keyspaces. A good rule of thumb is to use a keyspace per service to promote encapsulation. You'll learn about Cassandra's access control features in <<security>> that allow you to create a database user per keyspace, such that each service can be easily configured to have exclusive read and write access to all of the tables in its associated keyspace.

Next, you'll want to consider whether a given service will have its own dedicated Cassandra cluster or share a cluster with other services. <<service_mapping_to_clusters>> depicts a shared deployment in which Reservation and Inventory Services are using a shared cluster for data storage.

[[service_mapping_to_clusters]]
.Service mapping to clusters
image::images/cdg3_0711.png[]

Companies that use both microservice architectures and Cassandra at large scale, such as Netflix, are known to use dedicated clusters per service. The decision of how many clusters to use will depend on the workload of each service. A flexible approach is to use a mix of shared and dedicated clusters, in which services that have lower demand share a cluster, while services with higher demand are deployed with their own dedicated cluster. Sharing a cluster across multiple services makes sense when the usage patterns of the services do not conflict.

[[data_centers_and_load_balancing]]
==== Data Centers and Load Balancing
A second consideration is the selection of data centers where each service will be deployed. The corresponding cluster for a service should also have nodes in each data center where the service will be deployed, to enable the fastest possible access. <<multi_data_center_deployment>> shows a sample deployment across two data centers. The service instances should be made aware of the name of the local data center. The keyspace used by a service will need to be configured with a number of replicas to be stored per data center, assuming the `NetworkTopologyStrategy` is the replication strategy in use.

[[multi_data_center_deployment]]
.Multiple data center deployment
image::images/cdg3_0712.png[]

As you will learn in <<application_development>>, most of these options, such as keyspace names, database access credentials, and cluster topology, can be externalized from application code into configuration files that can be more readily changed. Even so, it's wise to begin thinking about these choices in the design phase.

==== Interactions Between Microservices
One question that arises when developing microservices that manage related types is how to maintain data consistency between the different types. If you want to maintain strict ownership of data by different microservices, how can you maintain a consistency relationship for data types owned by different services? Cassandra does not provide a mechanism to enforce transactions across table or keyspace boundaries. But this problem is not unique to Cassandra, since you'd have a similar design challenge whenever you need consistency between data types managed by different services, regardless of the backing store.

Let's look at the hotel application for an example. Given the separate services to manage inventory and reservation data, how do you ensure that the inventory records are correctly updated when a customer makes a reservation? Two common approaches to this challenge are shown in <<service_integration_patterns>>.

[[service_integration_patterns]]
.Service integration patterns
image::images/cdg3_0713.png[]

The approach on the left side is to create a Booking Service to help coordinate the changes to reservation and inventory data. This is an instance of a technique known as _orchestration_, often seen in architectures that distinguish between so-called _CRUD services_ (responsible for creating, reading, updating, and deleting a specific data type) and services that implement business processes. In this example, the Reservation and Inventory Services are more CRUD services, while the Booking Service implements the business process of booking a reservation, reserving inventory and possibly other activities such as notifying the customer and hotel.

An alternative approach is depicted on the right side of the figure, in which a message queue or streaming platform such as Apache Kafka is used to create a stream of data change events which can be consumed asynchronously by other services and applications. For example, the Inventory Service might choose to subscribe to events related to reservations published by the Reservation Service in order to make corresponding adjustments to inventory. Because there is no central entity orchestrating these changes, this approach is instead known as _choreography_. We'll examine integrating Cassandra with Kafka and other complementary technologies in more detail in <<migrating_and_integrating>>.

It's important to note that both orchestration and choreography can exhibit the tradeoffs between consistency, availability, and partition tolerance discussed in <<introducing_cassandra>>, and will require careful planning to address error cases such as service and infrastructure failures. While a detailed treatment of these approaches, including error handling scenarios, is beyond scope here, techniques and technologies are available to address error cases such as service failure and data inconsistency. These include:

* Using a distributed transaction framework to coordinate changes across multiple services and databases. This can be a good approach when strong consistency is required. (https://github.com/scalar-labs/scalardb)[Scalar DB] is an interesting library for implementing distributed ACID transactions that is built using Cassandra's lightweight transactions as a locking primitive.
* Using a distributed analytics tool such as Apache Spark to check data for consistency as a background processing task. This approach is useful as a backstop for catching data inconsistencies caused by software errors, in situations in which there is tolerance for temporary data inconsistencies.
* A variant of the event-based choreography approach is to leverage the change data capture (CDC) feature of a database as the source of events, rather than relying on a service to reliably persist data to a database and then post an event. This approach is typically used to guarantee highly consistent interactions at the interface between applications, although it could be used between individual services.

[[a_sample_application_killrvideo]]
.KillrVideo: A Reference Application for Video Sharing
****
The DataStax Developer Relations team and other contributors have created a video sharing application called (http://www.killrvideo.com/)[KillrVideo]. KillrVideo is an open source reference application built using features of Apache Cassandra and DataStax Enterprise, including Search and Graph. It uses a microservice architecture, providing another example of the design principles discussed here. You can download the source on (https://github.com/killrvideo/)[GitHub] and run your own copy of the application.
****

[[summary-id7]]
=== Summary

In this chapter, we've looked at why Cassandra is a natural fit within a microservice style architecture, and discussed how to ensure your architecture and data modeling processes can work together. We examined techniques for putting Cassandra-based services in context of other data models. Now that we have examined the design of a particular microservice architecture, we're ready to dive into the details of implementing applications using Cassandra.
